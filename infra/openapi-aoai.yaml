openapi: 3.0.1
info:
  title: AOAI
  description: Azure OpenAI APIs for ChatGPT
  version: '1.0'
servers:
  - url: https://apim-tutor17688.azure-api.net/aoai
paths:
  /convert/voice:
    post:
      tags:
        - converter
      summary: Voice to text
      description: This operation converts the voice input to text based on the given locale (`en-au` by default).
      operationId: ConvertVoiceToTextAsync
      requestBody:
        description: The input file data
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/voiceToTextRequestModel'
            example:
              locale: string
              input: string
              inputData: string
      responses:
        '200':
          description: The output file data
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/voiceToTextResponseModel'
              example:
                outputData: string
        '400':
          description: Either request header or body is invalid
          content:
            text/plain:
              schema:
                type: string
              examples:
                default:
                  value: 
        '500':
          description: Something went wrong
          content:
            text/plain:
              schema:
                type: string
              examples:
                default:
                  value: 

  /deployments:
    get:
      tags:
        - 'Deployments:'
      summary: Gets the list of deployments owned by the Azure OpenAI resource.
      description: Gets the list of deployments owned by the Azure OpenAI resource.
      operationId: Deployments_List
      parameters:
        - name: api-version
          in: query
          description: The requested API version.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeploymentList'
        '500':
          description: An error occurred.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'

  '/deployments/{deployment-id}/completions':
    post:
      summary: 'Creates a completion for the provided prompt, parameters and chosen model.'
      description: 'Creates a completion for the provided prompt, parameters and chosen model.'
      operationId: Completions_Create
      parameters:
        - name: deployment-id
          in: path
          required: true
          schema:
            type: string
            description: Deployment id of the model which was deployed.
            example: davinci
        - name: api-version
          in: query
          required: true
          schema:
            type: string
            description: api version
            example: '2022-12-01'
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                prompt:
                  oneOf:
                    - type: string
                      default: ''
                      nullable: true
                      example: This is a test.
                    - type: array
                      items:
                        type: string
                        default: ''
                        example: This is a test.
                      description: Array size minimum of 1 and maximum of 2048
                  description: "The prompt(s) to generate completions for, encoded as a string or array of strings.\nNote that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document. Maximum allowed size of string list is 2048."
                max_tokens:
                  type: integer
                  description: 'The token count of your prompt plus max_tokens cannot exceed the model''s context length. Most models have a context length of 2048 tokens (except for the newest models, which support 4096). Has minimum of 0.'
                  default: 16
                  nullable: true
                  example: 16
                temperature:
                  type: number
                  description: "What sampling temperature to use. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer.\nWe generally recommend altering this or top_p but not both."
                  default: 1
                  nullable: true
                  example: 1
                top_p:
                  type: number
                  description: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\nWe generally recommend altering this or temperature but not both."
                  default: 1
                  nullable: true
                  example: 1
                logit_bias:
                  type: object
                  description: 'Defaults to null. Modify the likelihood of specified tokens appearing in the completion. Accepts a json object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this tokenizer tool (which works for both GPT-2 and GPT-3) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token. As an example, you can pass {"50256" &#58; -100} to prevent the <|endoftext|> token from being generated.'
                user:
                  type: string
                  description: 'A unique identifier representing your end-user, which can help monitoring and detecting abuse'
                n:
                  type: integer
                  description: "How many completions to generate for each prompt. Minimum of 1 and maximum of 128 allowed.\nNote: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop."
                  default: 1
                  nullable: true
                  example: 1
                stream:
                  type: boolean
                  description: 'Whether to stream back partial progress. If set, tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a data: [DONE] message.'
                  default: false
                  nullable: true
                # logprobs:
                #   type: integer
                #   description: "Include the log probabilities on the logprobs most likely tokens, as well the chosen tokens. For example, if logprobs is 5, the API will return a list of the 5 most likely tokens. The API will always return the logprob of the sampled token, so there may be up to logprobs+1 elements in the response.\nMinimum of 0 and maximum of 5 allowed."
                #   default: 
                #   nullable: true
                model:
                  type: string
                  description: 'ID of the model to use. You can use the Models_List operation to see all of your available models, or see our Models_Get overview for descriptions of them.'
                  nullable: true
                  example: davinci
                suffix:
                  type: string
                  description: The suffix that comes after a completion of inserted text.
                  nullable: true
                # echo:
                #   type: boolean
                #   description: Echo back the prompt in addition to the completion
                #   default: false
                #   nullable: true
                stop:
                  oneOf:
                    - type: string
                      default: <|endoftext|>
                      nullable: true
                      example: "\n"
                    - type: array
                      items:
                        type: string
                        example:
                          - "\n"
                      description: Array minimum size of 1 and maximum of 4
                  description: Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.
                completion_config:
                  type: string
                  nullable: true
                cache_level:
                  type: integer
                  description: 'can be used to disable any server-side caching, 0=no cache, 1=prompt prefix enabled, 2=full cache'
                  nullable: true
                presence_penalty:
                  type: number
                  description: 'Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model''s likelihood to talk about new topics.'
                  default: 0
                frequency_penalty:
                  type: number
                  description: 'Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model''s likelihood to repeat the same line verbatim.'
                  default: 0
                # best_of:
                #   type: integer
                #   description: "Generates best_of completions server-side and returns the \"best\" (the one with the highest log probability per token). Results cannot be streamed.\nWhen used with n, best_of controls the number of candidate completions and n specifies how many to return â€“ best_of must be greater than n.\nNote: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop. Has maximum value of 128."
            example:
              prompt: "Negate the following sentence.The price for bubblegum increased on thursday.\n\n Negated Sentence:"
              max_tokens: 50
      responses:
        '200':
          description: OK
          headers:
            apim-request-id:
              description: Request ID for troubleshooting purposes
              schema:
                type: string
          content:
            application/json:
              schema:
                required:
                  - id
                  - object
                  - created
                  - model
                  - choices
                type: object
                properties:
                  id:
                    type: string
                  object:
                    type: string
                  created:
                    type: integer
                  model:
                    type: string
                  choices:
                    type: array
                    items:
                      type: object
                      properties:
                        text:
                          type: string
                        index:
                          type: integer
                        logprobs:
                          type: object
                          properties:
                            tokens:
                              type: array
                              items:
                                type: string
                            token_logprobs:
                              type: array
                              items:
                                type: number
                            top_logprobs:
                              type: array
                              items:
                                type: object
                                additionalProperties:
                                  type: number
                            text_offset:
                              type: array
                              items:
                                type: integer
                        finish_reason:
                          type: string
                  usage:
                    required:
                      - prompt_tokens
                      - total_tokens
                      - completion_tokens
                    type: object
                    properties:
                      completion_tokens:
                        type: number
                        format: int32
                      prompt_tokens:
                        type: number
                        format: int32
                      total_tokens:
                        type: number
                        format: int32
              example:
                model: davinci
                object: text_completion
                id: cmpl-4509KAos68kxOqpE2uYGw81j6m7uo
                created: 1637097562
                choices:
                  - index: 0
                    text: The price for bubblegum decreased on thursday.
                    logprobs: 
                    finish_reason: stop
        '400':
          description: Service unavailable
          headers:
            apim-request-id:
              description: Request ID for troubleshooting purposes
              schema:
                type: string
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/errorResponse'
              example:
                error:
                  code: string
                  message: string
                  param: string
                  type: string
        '500':
          description: Service unavailable
          headers:
            apim-request-id:
              description: Request ID for troubleshooting purposes
              schema:
                type: string
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/errorResponse'
              example:
                error:
                  code: string
                  message: string
                  param: string
                  type: string

components:
  schemas:
    Deployment:
      title: Deployment
      required:
        - model
        - scale_settings
      type: object
      properties:
        object:
          $ref: '#/components/schemas/TypeDiscriminator'
        status:
          $ref: '#/components/schemas/State'
        created_at:
          type: integer
          description: A timestamp when this job or item was created (in unix epochs).
          format: unixtime
          readOnly: true
        updated_at:
          type: integer
          description: A timestamp when this job or item was modified last (in unix epochs).
          format: unixtime
          readOnly: true
        id:
          type: string
          description: The identity of this item.
          readOnly: true
        model:
          minLength: 1
          type: string
          description: The OpenAI model identifier (model-id) to deploy. Can be a base model or a fine tune.
        owner:
          type: string
          description: The owner of this deployment. For Azure OpenAI only "organization-owner" is supported.
          readOnly: true
        scale_settings:
          $ref: '#/components/schemas/ScaleSettings'
        error:
          $ref: '#/components/schemas/Error'
      description: Deployments manage the reserved quota for Azure OpenAI models and make them available for inference requests.
    DeploymentList:
      title: DeploymentList
      type: object
      properties:
        object:
          $ref: '#/components/schemas/TypeDiscriminator'
        data:
          type: array
          items:
            $ref: '#/components/schemas/Deployment'
          description: The list of items.
      description: Represents a list of deployments.
    Error:
      title: Error
      required:
        - code
        - message
      type: object
      properties:
        code:
          $ref: '#/components/schemas/ErrorCode'
        message:
          minLength: 1
          type: string
          description: The message of this error.
        target:
          type: string
          description: The location where the error happened if available.
        details:
          type: array
          items:
            $ref: '#/components/schemas/Error'
          description: The error details if available.
        innererror:
          $ref: '#/components/schemas/InnerError'
      description: "Error content as defined in the Microsoft REST guidelines\r\n(https://github.com/microsoft/api-guidelines/blob/vNext/Guidelines.md#7102-error-condition-responses)."
    ErrorCode:
      title: ErrorCode
      enum:
        - conflict
        - invalidPayload
        - forbidden
        - notFound
        - unexpectedEntityState
        - itemDoesAlreadyExist
        - serviceUnavailable
        - internalFailure
        - quotaExceeded
        - jsonlValidationFailed
        - fileImportFailed
      type: string
      description: "Error codes as defined in the Microsoft REST guidelines\r\n(https://github.com/microsoft/api-guidelines/blob/vNext/Guidelines.md#7102-error-condition-responses)."
      x-ms-enum:
        name: ErrorCode
        modelAsString: true
        values:
          - value: conflict
            description: The requested operation conflicts with the current resource state.
          - value: invalidPayload
            description: The request data is invalid for this operation.
          - value: forbidden
            description: The operation is forbidden for the current user/api key.
          - value: notFound
            description: The resource is not found.
          - value: unexpectedEntityState
            description: The operation cannot be executed in the current resource's state.
          - value: itemDoesAlreadyExist
            description: The item does already exist.
          - value: serviceUnavailable
            description: The service is currently not available.
          - value: internalFailure
            description: Internal error. Please retry.
          - value: quotaExceeded
            description: Quota exceeded.
          - value: jsonlValidationFailed
            description: Validation of jsonl data failed.
          - value: fileImportFailed
            description: Import of file failed.
    ErrorResponse:
      title: ErrorResponse
      required:
        - error
      type: object
      properties:
        error:
          $ref: '#/components/schemas/Error'
      description: "Error response as defined in the Microsoft REST guidelines\r\n(https://github.com/microsoft/api-guidelines/blob/vNext/Guidelines.md#7102-error-condition-responses)."
    InnerError:
      title: InnerError
      type: object
      properties:
        code:
          $ref: '#/components/schemas/InnerErrorCode'
        innererror:
          $ref: '#/components/schemas/InnerError'
      description: "Inner error as defined in the Microsoft REST guidelines\r\n(https://github.com/microsoft/api-guidelines/blob/vNext/Guidelines.md#7102-error-condition-responses)."
    InnerErrorCode:
      title: InnerErrorCode
      enum:
        - invalidPayload
      type: string
      description: "Inner error codes as defined in the Microsoft REST guidelines\r\n(https://github.com/microsoft/api-guidelines/blob/vNext/Guidelines.md#7102-error-condition-responses)."
      x-ms-enum:
        name: InnerErrorCode
        modelAsString: true
        values:
          - value: invalidPayload
            description: The request data is invalid for this operation.
    ScaleSettings:
      title: ScaleSettings
      required:
        - scale_type
      type: object
      properties:
        scale_type:
          $ref: '#/components/schemas/ScaleType'
      description: The scale settings of a deployment. It defines the modes for scaling and the reserved capacity.
      discriminator:
        propertyName: scale_type
    ScaleType:
      title: ScaleType
      enum:
        - manual
        - standard
      type: string
      description: Defines how scaling operations will be executed.
      x-ms-enum:
        name: ScaleType
        modelAsString: true
        values:
          - value: manual
            description: Scaling of a deployment will happen by manually specifying the capacity of a model.
          - value: standard
            description: Scaling of a deployment will happen automatically based on usage.
    State:
      title: State
      enum:
        - notRunning
        - running
        - succeeded
        - canceled
        - failed
        - deleted
      type: string
      description: The state of a job or item.
      readOnly: true
      x-ms-enum:
        name: State
        modelAsString: true
        values:
          - value: notRunning
            description: The operation was created and is not queued to be processed in the future.
          - value: running
            description: The operation has started to be processed.
          - value: succeeded
            description: The operation has successfully be processed and is ready for consumption.
          - value: canceled
            description: The operation has been canceled and is incomplete.
          - value: failed
            description: The operation has completed processing with a failure and cannot be further consumed.
          - value: deleted
            description: The entity has been deleted but may still be referenced by other entities predating the deletion.
    TypeDiscriminator:
      title: TypeDiscriminator
      enum:
        - list
        - fine-tune
        - file
        - fine-tune-event
        - model
        - deployment
      type: string
      description: Defines the type of an object.
      readOnly: true
      x-ms-enum:
        name: TypeDiscriminator
        modelAsString: true
        values:
          - value: list
            description: This object represents a list of other objects.
          - value: fine-tune
            description: This object represents a fine tune job.
          - value: file
            description: This object represents a file.
          - value: fine-tune-event
            description: This object represents an event of a fine tune job.
          - value: model
            description: This object represents a model (can be a base models or fine tune job result).
          - value: deployment
            description: This object represents a deployment.

    errorResponse:
      type: object
      properties:
        error:
          type: object
          properties:
            code:
              type: string
            message:
              type: string
            param:
              type: string
            type:
              type: string

    voiceToTextRequestModel:
      type: object
      properties:
        locale:
          type: string
        input:
          type: string
        inputData:
          type: string
    voiceToTextResponseModel:
      type: object
      properties:
        outputData:
          type: string

  securitySchemes:
    apiKeyHeader:
      type: apiKey
      name: Ocp-Apim-Subscription-Key
      in: header
    apiKeyQuery:
      type: apiKey
      name: subscription-key
      in: query
security:
  - apiKeyHeader: [ ]
  - apiKeyQuery: [ ]